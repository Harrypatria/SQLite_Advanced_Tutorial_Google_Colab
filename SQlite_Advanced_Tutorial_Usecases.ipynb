{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Installation\n",
        "SQLite comes pre-installed with Python, so you don't need to install it separately. Just import the sqlite3 module:"
      ],
      "metadata": {
        "id": "2h-0e95i1aU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show tensorflow-metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZi70Ok0NyE-",
        "outputId": "9b91ec1e-cc5b-4796-f4f6-4d1369c693a1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: tensorflow-metadata\n",
            "Version: 1.16.1\n",
            "Summary: Library and standards for schema and statistics.\n",
            "Home-page: \n",
            "Author: Google Inc.\n",
            "Author-email: tensorflow-extended-dev@googlegroups.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: absl-py, googleapis-common-protos, protobuf\n",
            "Required-by: tensorflow-datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show grpcio-status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTPXFxFgN0yo",
        "outputId": "1a050c47-e4b6-4fbb-ff09-a9c73c93f39d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: grpcio-status\n",
            "Version: 1.71.0\n",
            "Summary: Status proto mapping for gRPC\n",
            "Home-page: https://grpc.io\n",
            "Author: The gRPC Authors\n",
            "Author-email: grpc-io@googlegroups.com\n",
            "License: Apache License 2.0\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: googleapis-common-protos, grpcio, protobuf\n",
            "Required-by: google-cloud-pubsub\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install protobuf==<compatible_version>"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_pMnPG-N2l5",
        "outputId": "51c8407e-6cea-4b65-abaf-6dd1a5ae4838"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 1: syntax error near unexpected token `newline'\n",
            "/bin/bash: -c: line 1: `pip install protobuf==<compatible_version>'\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install --force-reinstall mysql-connector-python==8.0.32"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "HcsBSLKQN4ZY",
        "outputId": "4c9c413a-f628-4e4d-d8be-7c4233e5fb4e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mysql-connector-python==8.0.32\n",
            "  Downloading mysql_connector_python-8.0.32-cp311-cp311-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting protobuf<=3.20.3,>=3.11.0 (from mysql-connector-python==8.0.32)\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Downloading mysql_connector_python-8.0.32-cp311-cp311-manylinux1_x86_64.whl (23.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, mysql-connector-python\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mysql-connector-python-8.0.32 protobuf-3.20.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "89ae7f83adba463fb3087d9756d9cd0a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "source": [
        "import sqlite3"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "EJVk8pNVNWxz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating a Database Connection\n",
        "You can create a connection to either an in-memory database or a file-based database:"
      ],
      "metadata": {
        "id": "Gg9MRMnL1rS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In-memory database (data is lost when connection is closed)\n",
        "conn_memory = sqlite3.connect(':memory:')\n",
        "\n",
        "# File-based database (data persists after connection is closed)\n",
        "conn_file = sqlite3.connect('example.db')\n",
        "\n",
        "# Create a cursor object to execute SQL statements\n",
        "cursor = conn_memory.cursor()"
      ],
      "metadata": {
        "id": "ymNCRKCO12Ns"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Operations\n",
        "#### Creating Tables\n",
        "Tables are created using the SQL CREATE TABLE statement:"
      ],
      "metadata": {
        "id": "i5FZqWc51w-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a table named 'employees'\n",
        "cursor.execute('''\n",
        "CREATE TABLE employees (\n",
        "    id INTEGER PRIMARY KEY,\n",
        "    name TEXT NOT NULL,\n",
        "    department TEXT,\n",
        "    salary REAL,\n",
        "    hire_date TEXT\n",
        ")\n",
        "''')\n",
        "\n",
        "# Commit the changes\n",
        "conn_memory.commit()"
      ],
      "metadata": {
        "id": "nvemZ-kJ10G_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inserting Data\n",
        "You can insert data using the SQL INSERT INTO statement:"
      ],
      "metadata": {
        "id": "cEttg8W116F-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Single row insertion\n",
        "cursor.execute(\"INSERT INTO employees (name, department, salary, hire_date) VALUES ('Alice', 'Sales', 60000, '2022-01-15')\")\n",
        "\n",
        "# Multiple row insertion using executemany\n",
        "employees_data = [\n",
        "    ('Bob', 'Marketing', 75000, '2022-02-10'),\n",
        "    ('Charlie', 'Engineering', 90000, '2021-11-01'),\n",
        "    ('Diana', 'HR', 65000, '2022-03-20'),\n",
        "    ('Eva', 'Engineering', 95000, '2021-08-15')\n",
        "]\n",
        "\n",
        "cursor.executemany(\"INSERT INTO employees (name, department, salary, hire_date) VALUES (?, ?, ?, ?)\", employees_data)\n",
        "\n",
        "# Commit the changes\n",
        "conn_memory.commit()"
      ],
      "metadata": {
        "id": "58YGZ0YV1tYz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Querying Data\n",
        "Retrieve data using the SQL SELECT statement:"
      ],
      "metadata": {
        "id": "XcW45Fc62BOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch all rows\n",
        "cursor.execute(\"SELECT * FROM employees\")\n",
        "all_employees = cursor.fetchall()\n",
        "print(\"All employees:\")\n",
        "for employee in all_employees:\n",
        "    print(employee)\n",
        "\n",
        "# Fetch rows with a condition\n",
        "cursor.execute(\"SELECT name, salary FROM employees WHERE department = 'Engineering'\")\n",
        "engineering_employees = cursor.fetchall()\n",
        "print(\"\\nEngineering employees:\")\n",
        "for employee in engineering_employees:\n",
        "    print(f\"Name: {employee[0]}, Salary: ${employee[1]}\")\n",
        "\n",
        "# Fetch a single row\n",
        "cursor.execute(\"SELECT * FROM employees WHERE id = 1\")\n",
        "first_employee = cursor.fetchone()\n",
        "print(\"\\nFirst employee:\", first_employee)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7etVc0Pt2D5t",
        "outputId": "32698322-76c6-4581-e9d9-9d267600cf7f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All employees:\n",
            "(1, 'Alice', 'Sales', 60000.0, '2022-01-15')\n",
            "(2, 'Bob', 'Marketing', 75000.0, '2022-02-10')\n",
            "(3, 'Charlie', 'Engineering', 90000.0, '2021-11-01')\n",
            "(4, 'Diana', 'HR', 65000.0, '2022-03-20')\n",
            "(5, 'Eva', 'Engineering', 95000.0, '2021-08-15')\n",
            "\n",
            "Engineering employees:\n",
            "Name: Charlie, Salary: $90000.0\n",
            "Name: Eva, Salary: $95000.0\n",
            "\n",
            "First employee: (1, 'Alice', 'Sales', 60000.0, '2022-01-15')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Updating and Deleting Data\n",
        "Modify existing data with UPDATE and DELETE statements:"
      ],
      "metadata": {
        "id": "mzhaLUGu2HC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Update a record\n",
        "cursor.execute(\"UPDATE employees SET salary = 65000 WHERE name = 'Alice'\")\n",
        "\n",
        "# Delete a record\n",
        "cursor.execute(\"DELETE FROM employees WHERE name = 'Diana'\")\n",
        "\n",
        "# Commit the changes\n",
        "conn_memory.commit()\n",
        "\n",
        "# Verify the changes\n",
        "cursor.execute(\"SELECT * FROM employees\")\n",
        "updated_employees = cursor.fetchall()\n",
        "print(\"\\nAfter updates:\")\n",
        "for employee in updated_employees:\n",
        "    print(employee)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqm41Gh32GUz",
        "outputId": "6a17ab42-c4b2-4039-be45-c7a95463f976"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After updates:\n",
            "(1, 'Alice', 'Sales', 65000.0, '2022-01-15')\n",
            "(2, 'Bob', 'Marketing', 75000.0, '2022-02-10')\n",
            "(3, 'Charlie', 'Engineering', 90000.0, '2021-11-01')\n",
            "(5, 'Eva', 'Engineering', 95000.0, '2021-08-15')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Intermediate Operations\n",
        "#### Using SQLite with Pandas\n",
        "SQLite works seamlessly with pandas, allowing you to read SQL queries directly into DataFrames:"
      ],
      "metadata": {
        "id": "IuWZLDks2L6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read query results into a DataFrame\n",
        "df = pd.read_sql_query(\"SELECT * FROM employees\", conn_memory)\n",
        "print(\"\\nEmployees DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Calculate statistics\n",
        "print(\"\\nSalary statistics:\")\n",
        "print(df['salary'].describe())\n",
        "\n",
        "# Group by department\n",
        "dept_stats = df.groupby('department').agg({\n",
        "    'salary': ['mean', 'min', 'max', 'count']\n",
        "})\n",
        "print(\"\\nDepartment statistics:\")\n",
        "print(dept_stats)\n",
        "\n",
        "# Write DataFrame back to SQLite\n",
        "df_new = pd.DataFrame({\n",
        "    'name': ['Frank', 'Grace'],\n",
        "    'department': ['Sales', 'Marketing'],\n",
        "    'salary': [70000, 72000],\n",
        "    'hire_date': ['2022-05-01', '2022-04-15']\n",
        "})\n",
        "\n",
        "df_new.to_sql('employees', conn_memory, if_exists='append', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfSg63pG2Ogj",
        "outputId": "4d61750e-a3df-4d6f-b173-87d92a96935b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Employees DataFrame:\n",
            "   id     name   department   salary   hire_date\n",
            "0   1    Alice        Sales  65000.0  2022-01-15\n",
            "1   2      Bob    Marketing  75000.0  2022-02-10\n",
            "2   3  Charlie  Engineering  90000.0  2021-11-01\n",
            "3   5      Eva  Engineering  95000.0  2021-08-15\n",
            "\n",
            "Salary statistics:\n",
            "count        4.000000\n",
            "mean     81250.000000\n",
            "std      13768.926368\n",
            "min      65000.000000\n",
            "25%      72500.000000\n",
            "50%      82500.000000\n",
            "75%      91250.000000\n",
            "max      95000.000000\n",
            "Name: salary, dtype: float64\n",
            "\n",
            "Department statistics:\n",
            "              salary                        \n",
            "                mean      min      max count\n",
            "department                                  \n",
            "Engineering  92500.0  90000.0  95000.0     2\n",
            "Marketing    75000.0  75000.0  75000.0     1\n",
            "Sales        65000.0  65000.0  65000.0     1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transactions\n",
        "Transactions ensure that a series of operations are atomic (all succeed or all fail):"
      ],
      "metadata": {
        "id": "AjzWmfLL2ZMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Start a transaction\n",
        "    conn_memory.execute(\"BEGIN TRANSACTION\")\n",
        "\n",
        "    # Perform multiple operations\n",
        "    conn_memory.execute(\"UPDATE employees SET salary = salary * 1.1 WHERE department = 'Sales'\")\n",
        "    conn_memory.execute(\"INSERT INTO employees (name, department, salary, hire_date) VALUES ('Helen', 'Finance', 85000, '2022-06-01')\")\n",
        "\n",
        "    # Simulate an error (uncomment to test rollback)\n",
        "    # raise Exception(\"Simulated error\")\n",
        "\n",
        "    # Commit the transaction\n",
        "    conn_memory.execute(\"COMMIT\")\n",
        "    print(\"\\nTransaction committed successfully\")\n",
        "\n",
        "except Exception as e:\n",
        "    # Roll back on error\n",
        "    conn_memory.execute(\"ROLLBACK\")\n",
        "    print(f\"\\nTransaction rolled back due to error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0Unir0v2boQ",
        "outputId": "135f2a43-a524-4daf-eb60-01c356acc08f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Transaction committed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using SQLite with Python Functions\n",
        "You can create custom SQLite functions using Python:"
      ],
      "metadata": {
        "id": "x-aqpw3P2hct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Register a custom function for calculating years of service\n",
        "def years_of_service(hire_date):\n",
        "    from datetime import datetime\n",
        "    if hire_date:\n",
        "        hire_date = datetime.strptime(hire_date, '%Y-%m-%d')\n",
        "        today = datetime.now()\n",
        "        return (today - hire_date).days / 365.25\n",
        "    return None\n",
        "\n",
        "# Register the function with SQLite\n",
        "conn_memory.create_function(\"YEARS_OF_SERVICE\", 1, years_of_service)\n",
        "\n",
        "# Use the custom function in a query\n",
        "cursor.execute(\"\"\"\n",
        "SELECT name, department, hire_date, ROUND(YEARS_OF_SERVICE(hire_date), 1) as years\n",
        "FROM employees\n",
        "ORDER BY years DESC\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\nYears of service:\")\n",
        "for row in cursor.fetchall():\n",
        "    print(f\"{row[0]} ({row[1]}): {row[2]} - {row[3]} years\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBD52ofj2jTk",
        "outputId": "757ddfe3-2183-4099-ee75-5a5583b243c3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Years of service:\n",
            "Eva (Engineering): 2021-08-15 - 3.6 years\n",
            "Charlie (Engineering): 2021-11-01 - 3.4 years\n",
            "Alice (Sales): 2022-01-15 - 3.2 years\n",
            "Bob (Marketing): 2022-02-10 - 3.1 years\n",
            "Grace (Marketing): 2022-04-15 - 3.0 years\n",
            "Frank (Sales): 2022-05-01 - 2.9 years\n",
            "Helen (Finance): 2022-06-01 - 2.8 years\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Foreign Keys and Relationships\n",
        "Create related tables with foreign key constraints:"
      ],
      "metadata": {
        "id": "CeklGiAi2lyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable foreign key support\n",
        "conn_memory.execute(\"PRAGMA foreign_keys = ON\")\n",
        "\n",
        "# Create departments table\n",
        "cursor.execute('''\n",
        "CREATE TABLE departments (\n",
        "    id INTEGER PRIMARY KEY,\n",
        "    name TEXT UNIQUE NOT NULL,\n",
        "    location TEXT\n",
        ")\n",
        "''')\n",
        "\n",
        "# Create a new employees table with a foreign key\n",
        "cursor.execute('''\n",
        "CREATE TABLE employees_new (\n",
        "    id INTEGER PRIMARY KEY,\n",
        "    name TEXT NOT NULL,\n",
        "    department_id INTEGER,\n",
        "    salary REAL,\n",
        "    hire_date TEXT,\n",
        "    FOREIGN KEY (department_id) REFERENCES departments (id)\n",
        ")\n",
        "''')\n",
        "\n",
        "# Insert departments\n",
        "departments_data = [\n",
        "    (1, 'Sales', 'New York'),\n",
        "    (2, 'Marketing', 'Los Angeles'),\n",
        "    (3, 'Engineering', 'San Francisco'),\n",
        "    (4, 'HR', 'Chicago'),\n",
        "    (5, 'Finance', 'Boston')\n",
        "]\n",
        "\n",
        "cursor.executemany(\"INSERT INTO departments (id, name, location) VALUES (?, ?, ?)\", departments_data)\n",
        "\n",
        "# Insert employees with department_id\n",
        "employees_with_dept = [\n",
        "    ('Alice', 1, 65000, '2022-01-15'),\n",
        "    ('Bob', 2, 75000, '2022-02-10'),\n",
        "    ('Charlie', 3, 90000, '2021-11-01'),\n",
        "    ('Eva', 3, 95000, '2021-08-15'),\n",
        "    ('Frank', 1, 70000, '2022-05-01'),\n",
        "    ('Grace', 2, 72000, '2022-04-15'),\n",
        "    ('Helen', 5, 85000, '2022-06-01')\n",
        "]\n",
        "\n",
        "cursor.executemany(\"INSERT INTO employees_new (name, department_id, salary, hire_date) VALUES (?, ?, ?, ?)\", employees_with_dept)\n",
        "\n",
        "# Join tables to get employee and department information\n",
        "cursor.execute('''\n",
        "SELECT e.name, d.name as department, d.location, e.salary\n",
        "FROM employees_new e\n",
        "JOIN departments d ON e.department_id = d.id\n",
        "ORDER BY e.salary DESC\n",
        "''')\n",
        "\n",
        "print(\"\\nEmployees with department details:\")\n",
        "for row in cursor.fetchall():\n",
        "    print(f\"{row[0]} works in {row[1]} ({row[2]}) with salary ${row[3]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owmkitbY2nv5",
        "outputId": "a8bb2fff-631f-45ca-80a9-3a29f013ab9e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Employees with department details:\n",
            "Eva works in Engineering (San Francisco) with salary $95000.0\n",
            "Charlie works in Engineering (San Francisco) with salary $90000.0\n",
            "Helen works in Finance (Boston) with salary $85000.0\n",
            "Bob works in Marketing (Los Angeles) with salary $75000.0\n",
            "Grace works in Marketing (Los Angeles) with salary $72000.0\n",
            "Frank works in Sales (New York) with salary $70000.0\n",
            "Alice works in Sales (New York) with salary $65000.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Advanced Operations\n",
        "#### Indexes for Performance\n",
        "Create indexes to improve query performance:"
      ],
      "metadata": {
        "id": "XoMBHz7b2uVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an index on the department_id column\n",
        "cursor.execute(\"CREATE INDEX idx_employees_department ON employees_new(department_id)\")\n",
        "\n",
        "# Create a composite index on department_id and salary\n",
        "cursor.execute(\"CREATE INDEX idx_dept_salary ON employees_new(department_id, salary)\")\n",
        "\n",
        "# Measure query performance before and after indexing\n",
        "import time\n",
        "\n",
        "# Without using index\n",
        "start_time = time.time()\n",
        "cursor.execute(\"SELECT * FROM employees_new WHERE salary > 80000\")\n",
        "cursor.fetchall()\n",
        "print(f\"\\nQuery without optimized index: {time.time() - start_time:.6f} seconds\")\n",
        "\n",
        "# Using index\n",
        "start_time = time.time()\n",
        "cursor.execute(\"SELECT * FROM employees_new WHERE department_id = 3 AND salary > 80000\")\n",
        "cursor.fetchall()\n",
        "print(f\"Query with optimized index: {time.time() - start_time:.6f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acVTnaN32yTq",
        "outputId": "a7fbb704-450f-4d31-9559-a42a4a22b40c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query without optimized index: 0.000168 seconds\n",
            "Query with optimized index: 0.000210 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Full-Text Search\n",
        "Set up full-text search for efficient text searching:"
      ],
      "metadata": {
        "id": "xNsR0HN022IB"
      }
    },
    {
      "source": [
        "# Check if the table exists before creating it\n",
        "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name='employee_fts'\")\n",
        "table_exists = cursor.fetchone()\n",
        "\n",
        "# Create the table only if it doesn't exist\n",
        "if not table_exists:\n",
        "    cursor.execute('''\n",
        "    CREATE VIRTUAL TABLE employee_fts USING fts5(\n",
        "        name,\n",
        "        department,\n",
        "        bio,\n",
        "        content='employees_new',\n",
        "        content_rowid='id'\n",
        "    )\n",
        "    ''')\n",
        "    print(\"Table 'employee_fts' created successfully.\")\n",
        "else:\n",
        "    print(\"Table 'employee_fts' already exists.\")\n",
        "\n",
        "# ... (rest of your code) ..."
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TfHU5PC2-s7",
        "outputId": "cf190166-8163-4de9-b2b0-6e6abe71624d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table 'employee_fts' created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BLOB Storage\n",
        "Store binary data like images in SQLite:"
      ],
      "metadata": {
        "id": "1d1qloar3Lp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a table for storing files\n",
        "cursor.execute('''\n",
        "CREATE TABLE files (\n",
        "    id INTEGER PRIMARY KEY,\n",
        "    filename TEXT NOT NULL,\n",
        "    file_type TEXT NOT NULL,\n",
        "    data BLOB NOT NULL,\n",
        "    upload_date TEXT NOT NULL\n",
        ")\n",
        "''')\n",
        "\n",
        "# Function to insert a file into the database\n",
        "def insert_file(filename, file_type, file_data):\n",
        "    from datetime import datetime\n",
        "    upload_date = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "    cursor.execute('INSERT INTO files (filename, file_type, data, upload_date) VALUES (?, ?, ?, ?)',\n",
        "                  (filename, file_type, file_data, upload_date))\n",
        "    conn_memory.commit()\n",
        "    return cursor.lastrowid\n",
        "\n",
        "# Function to retrieve a file from the database\n",
        "def get_file(file_id):\n",
        "    cursor.execute('SELECT filename, file_type, data, upload_date FROM files WHERE id = ?', (file_id,))\n",
        "    return cursor.fetchone()\n",
        "\n",
        "# Example: Generate some binary data (simulating an image)\n",
        "sample_data = b'\\x89PNG\\r\\n\\x1a\\n' + bytes([0] * 1000)  # Fake PNG header + data\n",
        "\n",
        "# Store the file\n",
        "file_id = insert_file('sample.png', 'image/png', sample_data)\n",
        "print(f\"\\nFile stored with ID: {file_id}\")\n",
        "\n",
        "# Retrieve the file\n",
        "file_info = get_file(file_id)\n",
        "print(f\"Retrieved file: {file_info[0]}, Type: {file_info[1]}, Size: {len(file_info[2])} bytes, Uploaded: {file_info[3]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bSMCT823Rm5",
        "outputId": "b2f655e0-072f-42fe-e1a1-5bb7168137f6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "File stored with ID: 1\n",
            "Retrieved file: sample.png, Type: image/png, Size: 1008 bytes, Uploaded: 2025-03-29 12:27:47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use Cases\n",
        "#### Simple Application Database\n",
        "Example of using SQLite for a simple task manager application:"
      ],
      "metadata": {
        "id": "ZTbSyTGP3Va5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a task manager database\n",
        "tasks_conn = sqlite3.connect('tasks.db')\n",
        "tasks_cursor = tasks_conn.cursor()\n",
        "\n",
        "# Create tables\n",
        "tasks_cursor.execute('''\n",
        "CREATE TABLE IF NOT EXISTS categories (\n",
        "    id INTEGER PRIMARY KEY,\n",
        "    name TEXT NOT NULL UNIQUE\n",
        ")\n",
        "''')\n",
        "\n",
        "tasks_cursor.execute('''\n",
        "CREATE TABLE IF NOT EXISTS tasks (\n",
        "    id INTEGER PRIMARY KEY,\n",
        "    title TEXT NOT NULL,\n",
        "    description TEXT,\n",
        "    due_date TEXT,\n",
        "    priority INTEGER DEFAULT 0,\n",
        "    completed INTEGER DEFAULT 0,\n",
        "    category_id INTEGER,\n",
        "    created_at TEXT DEFAULT CURRENT_TIMESTAMP,\n",
        "    FOREIGN KEY (category_id) REFERENCES categories (id)\n",
        ")\n",
        "''')\n",
        "\n",
        "# Add sample data\n",
        "categories = [('Work',), ('Personal',), ('Study',), ('Health',)]\n",
        "tasks_cursor.executemany(\"INSERT OR IGNORE INTO categories (name) VALUES (?)\", categories)\n",
        "\n",
        "tasks = [\n",
        "    ('Complete SQLite tutorial', 'Finish the comprehensive guide', '2023-03-30', 2, 0, 3),\n",
        "    ('Prepare presentation', 'Create slides for team meeting', '2023-03-25', 3, 0, 1),\n",
        "    ('Gym workout', '30 minutes cardio + strength training', '2023-03-24', 1, 0, 4),\n",
        "    ('Buy groceries', 'Milk, eggs, bread, vegetables', '2023-03-23', 2, 1, 2)\n",
        "]\n",
        "\n",
        "tasks_cursor.executemany('''\n",
        "INSERT INTO tasks (title, description, due_date, priority, completed, category_id)\n",
        "VALUES (?, ?, ?, ?, ?, ?)\n",
        "''', tasks)\n",
        "\n",
        "tasks_conn.commit()\n",
        "\n",
        "# Task manager functions\n",
        "def add_task(title, description, due_date, priority, category_id):\n",
        "    tasks_cursor.execute('''\n",
        "    INSERT INTO tasks (title, description, due_date, priority, category_id)\n",
        "    VALUES (?, ?, ?, ?, ?)\n",
        "    ''', (title, description, due_date, priority, category_id))\n",
        "    tasks_conn.commit()\n",
        "    return tasks_cursor.lastrowid\n",
        "\n",
        "def get_tasks(completed=None, category_id=None):\n",
        "    query = \"SELECT t.id, t.title, t.description, t.due_date, t.priority, t.completed, c.name as category \"\n",
        "    query += \"FROM tasks t LEFT JOIN categories c ON t.category_id = c.id WHERE 1=1 \"\n",
        "    params = []\n",
        "\n",
        "    if completed is not None:\n",
        "        query += \"AND t.completed = ? \"\n",
        "        params.append(completed)\n",
        "\n",
        "    if category_id is not None:\n",
        "        query += \"AND t.category_id = ? \"\n",
        "        params.append(category_id)\n",
        "\n",
        "    query += \"ORDER BY t.due_date, t.priority DESC\"\n",
        "\n",
        "    tasks_cursor.execute(query, params)\n",
        "    return tasks_cursor.fetchall()\n",
        "\n",
        "def mark_completed(task_id, completed=1):\n",
        "    tasks_cursor.execute(\"UPDATE tasks SET completed = ? WHERE id = ?\", (completed, task_id))\n",
        "    tasks_conn.commit()\n",
        "    return tasks_cursor.rowcount\n",
        "\n",
        "# Demo the task manager\n",
        "print(\"\\nTask Manager Demo:\")\n",
        "print(\"\\nAll tasks:\")\n",
        "for task in get_tasks():\n",
        "    status = \"✓\" if task[5] else \"□\"\n",
        "    print(f\"{status} {task[1]} (Due: {task[3]}, Priority: {task[4]}, Category: {task[6]})\")\n",
        "\n",
        "print(\"\\nAdding a new task...\")\n",
        "new_task_id = add_task(\"Buy birthday gift\", \"Gift for mom's birthday\", \"2023-03-27\", 2, 2)\n",
        "print(f\"New task added with ID: {new_task_id}\")\n",
        "\n",
        "print(\"\\nMarking a task as completed...\")\n",
        "mark_completed(1)\n",
        "print(\"Task 1 marked as completed\")\n",
        "\n",
        "print(\"\\nPending tasks:\")\n",
        "for task in get_tasks(completed=0):\n",
        "    print(f\"□ {task[1]} (Due: {task[3]}, Priority: {task[4]}, Category: {task[6]})\")\n",
        "\n",
        "# Close the connection when done\n",
        "tasks_conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f3yrw914J65",
        "outputId": "d089a000-3b57-4df7-96ab-f93441eea273"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Task Manager Demo:\n",
            "\n",
            "All tasks:\n",
            "✓ Buy groceries (Due: 2023-03-23, Priority: 2, Category: Personal)\n",
            "□ Gym workout (Due: 2023-03-24, Priority: 1, Category: Health)\n",
            "□ Prepare presentation (Due: 2023-03-25, Priority: 3, Category: Work)\n",
            "□ Complete SQLite tutorial (Due: 2023-03-30, Priority: 2, Category: Study)\n",
            "\n",
            "Adding a new task...\n",
            "New task added with ID: 5\n",
            "\n",
            "Marking a task as completed...\n",
            "Task 1 marked as completed\n",
            "\n",
            "Pending tasks:\n",
            "□ Gym workout (Due: 2023-03-24, Priority: 1, Category: Health)\n",
            "□ Prepare presentation (Due: 2023-03-25, Priority: 3, Category: Work)\n",
            "□ Buy birthday gift (Due: 2023-03-27, Priority: 2, Category: Personal)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Analysis Pipeline\n",
        "Using SQLite as part of a data analysis pipeline:"
      ],
      "metadata": {
        "id": "q-LO8BgT4Nvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sqlite3\n",
        "\n",
        "# Create a database for sales data\n",
        "sales_conn = sqlite3.connect('sales_analysis.db')\n",
        "\n",
        "# Create tables for sales data\n",
        "sales_conn.execute('''\n",
        "CREATE TABLE IF NOT EXISTS regions (\n",
        "    id INTEGER PRIMARY KEY,\n",
        "    name TEXT NOT NULL,\n",
        "    country TEXT NOT NULL\n",
        ")\n",
        "''')\n",
        "\n",
        "sales_conn.execute('''\n",
        "CREATE TABLE IF NOT EXISTS products (\n",
        "    id INTEGER PRIMARY KEY,\n",
        "    name TEXT NOT NULL,\n",
        "    category TEXT NOT NULL,\n",
        "    price REAL NOT NULL\n",
        ")\n",
        "''')\n",
        "\n",
        "sales_conn.execute('''\n",
        "CREATE TABLE IF NOT EXISTS sales (\n",
        "    id INTEGER PRIMARY KEY,\n",
        "    date TEXT NOT NULL,\n",
        "    product_id INTEGER NOT NULL,\n",
        "    region_id INTEGER NOT NULL,\n",
        "    quantity INTEGER NOT NULL,\n",
        "    FOREIGN KEY (product_id) REFERENCES products (id),\n",
        "    FOREIGN KEY (region_id) REFERENCES regions (id)\n",
        ")\n",
        "''')\n",
        "\n",
        "# Insert sample data\n",
        "regions = [\n",
        "    (1, 'Northeast', 'USA'),\n",
        "    (2, 'Southeast', 'USA'),\n",
        "    (3, 'Midwest', 'USA'),\n",
        "    (4, 'West', 'USA'),\n",
        "    (5, 'Central', 'Canada'),\n",
        "    (6, 'Eastern', 'Canada')\n",
        "]\n",
        "\n",
        "products = [\n",
        "    (1, 'Laptop', 'Electronics', 1200),\n",
        "    (2, 'Smartphone', 'Electronics', 800),\n",
        "    (3, 'Tablet', 'Electronics', 500),\n",
        "    (4, 'Desk Chair', 'Furniture', 250),\n",
        "    (5, 'Desk', 'Furniture', 350),\n",
        "    (6, 'Bookshelf', 'Furniture', 150)\n",
        "]\n",
        "\n",
        "# Generate random sales data\n",
        "np.random.seed(42)\n",
        "sales_data = []\n",
        "sale_id = 1\n",
        "\n",
        "for month in range(1, 13):\n",
        "    for day in range(1, 29, 7):  # Weekly data\n",
        "        for product_id in range(1, 7):\n",
        "            for region_id in range(1, 7):\n",
        "                # Random quantity between 1 and 20\n",
        "                quantity = np.random.randint(1, 21)\n",
        "                date = f\"2022-{month:02d}-{day:02d}\"\n",
        "                sales_data.append((sale_id, date, product_id, region_id, quantity))\n",
        "                sale_id += 1\n",
        "\n",
        "# Insert data\n",
        "sales_conn.executemany(\"INSERT INTO regions VALUES (?, ?, ?)\", regions)\n",
        "sales_conn.executemany(\"INSERT INTO products VALUES (?, ?, ?, ?)\", products)\n",
        "sales_conn.executemany(\"INSERT INTO sales VALUES (?, ?, ?, ?, ?)\", sales_data)\n",
        "sales_conn.commit()\n",
        "\n",
        "# Query for analysis\n",
        "sales_query = '''\n",
        "SELECT\n",
        "    s.date,\n",
        "    r.name as region,\n",
        "    r.country,\n",
        "    p.name as product,\n",
        "    p.category,\n",
        "    p.price,\n",
        "    s.quantity,\n",
        "    p.price * s.quantity as revenue\n",
        "FROM sales s\n",
        "JOIN products p ON s.product_id = p.id\n",
        "JOIN regions r ON s.region_id = r.id\n",
        "ORDER BY s.date\n",
        "'''\n",
        "\n",
        "# Load into pandas\n",
        "sales_df = pd.read_sql_query(sales_query, sales_conn)\n",
        "\n",
        "# Basic analysis\n",
        "print(\"\\nSales Data Analysis:\")\n",
        "print(f\"Total records: {len(sales_df)}\")\n",
        "print(f\"Date range: {sales_df['date'].min()} to {sales_df['date'].max()}\")\n",
        "print(f\"Total revenue: ${sales_df['revenue'].sum():,.2f}\")\n",
        "\n",
        "# Monthly revenue\n",
        "sales_df['date'] = pd.to_datetime(sales_df['date'])\n",
        "sales_df['month'] = sales_df['date'].dt.strftime('%Y-%m')\n",
        "monthly_revenue = sales_df.groupby('month')['revenue'].sum().reset_index()\n",
        "\n",
        "print(\"\\nMonthly Revenue:\")\n",
        "for _, row in monthly_revenue.iterrows():\n",
        "    print(f\"{row['month']}: ${row['revenue']:,.2f}\")\n",
        "\n",
        "# Revenue by category\n",
        "category_revenue = sales_df.groupby('category')['revenue'].sum().reset_index()\n",
        "print(\"\\nRevenue by Category:\")\n",
        "for _, row in category_revenue.iterrows():\n",
        "    print(f\"{row['category']}: ${row['revenue']:,.2f}\")\n",
        "\n",
        "# Revenue by region\n",
        "region_revenue = sales_df.groupby(['region', 'country'])['revenue'].sum().reset_index()\n",
        "print(\"\\nRevenue by Region:\")\n",
        "for _, row in region_revenue.iterrows():\n",
        "    print(f\"{row['region']} ({row['country']}): ${row['revenue']:,.2f}\")\n",
        "\n",
        "# Store aggregate data back in SQLite\n",
        "monthly_revenue.to_sql('monthly_revenue', sales_conn, if_exists='replace', index=False)\n",
        "category_revenue.to_sql('category_revenue', sales_conn, if_exists='replace', index=False)\n",
        "region_revenue.to_sql('region_revenue', sales_conn, if_exists='replace', index=False)\n",
        "\n",
        "# Close the connection\n",
        "sales_conn.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nJZwERB4PQM",
        "outputId": "107fc53e-4f79-407b-9272-9389e3f57311"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sales Data Analysis:\n",
            "Total records: 1728\n",
            "Date range: 2022-01-01 to 2022-12-22\n",
            "Total revenue: $9,568,500.00\n",
            "\n",
            "Monthly Revenue:\n",
            "2022-01: $772,950.00\n",
            "2022-02: $781,550.00\n",
            "2022-03: $782,700.00\n",
            "2022-04: $845,200.00\n",
            "2022-05: $730,200.00\n",
            "2022-06: $797,200.00\n",
            "2022-07: $748,300.00\n",
            "2022-08: $781,550.00\n",
            "2022-09: $815,500.00\n",
            "2022-10: $816,850.00\n",
            "2022-11: $878,550.00\n",
            "2022-12: $817,950.00\n",
            "\n",
            "Revenue by Category:\n",
            "Electronics: $7,325,800.00\n",
            "Furniture: $2,242,700.00\n",
            "\n",
            "Revenue by Region:\n",
            "Central (Canada): $1,550,900.00\n",
            "Eastern (Canada): $1,653,100.00\n",
            "Midwest (USA): $1,596,950.00\n",
            "Northeast (USA): $1,607,850.00\n",
            "Southeast (USA): $1,567,400.00\n",
            "West (USA): $1,592,300.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedded Database\n",
        "Example of using SQLite as an embedded database for a simple IoT application:"
      ],
      "metadata": {
        "id": "ISTPb4734TOn"
      }
    },
    {
      "source": [
        "import sqlite3\n",
        "import datetime\n",
        "import random\n",
        "import time\n",
        "\n",
        "# Create a database for sensor data\n",
        "iot_db = sqlite3.connect('iot_sensors.db')\n",
        "\n",
        "# Create tables\n",
        "iot_db.execute('''\n",
        "CREATE TABLE IF NOT EXISTS devices (\n",
        "    id INTEGER PRIMARY KEY,\n",
        "    name TEXT NOT NULL,\n",
        "    location TEXT,\n",
        "    type TEXT NOT NULL,\n",
        "    active INTEGER DEFAULT 1\n",
        ")\n",
        "''')\n",
        "\n",
        "iot_db.execute('''\n",
        "CREATE TABLE IF NOT EXISTS sensor_data (\n",
        "    id INTEGER PRIMARY KEY,\n",
        "    device_id INTEGER NOT NULL,\n",
        "    timestamp TEXT NOT NULL,\n",
        "    temperature REAL,\n",
        "    humidity REAL,\n",
        "    pressure REAL,\n",
        "    light_level REAL,\n",
        "    FOREIGN KEY (device_id) REFERENCES devices (id)\n",
        ")\n",
        "''')\n",
        "\n",
        "# Insert sample devices\n",
        "devices = [\n",
        "    (1, 'Living Room Sensor', 'Living Room', 'Environmental', 1),\n",
        "    (2, 'Kitchen Sensor', 'Kitchen', 'Environmental', 1),\n",
        "    (3, 'Outdoor Sensor', 'Backyard', 'Weather', 1),\n",
        "    (4, 'Bedroom Sensor', 'Bedroom', 'Environmental', 1)\n",
        "]\n",
        "\n",
        "iot_db.executemany(\"INSERT OR IGNORE INTO devices VALUES (?, ?, ?, ?, ?)\", devices)\n",
        "iot_db.commit()\n",
        "\n",
        "# Function to simulate sensor readings\n",
        "def generate_sensor_reading(device_id):\n",
        "    now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    # Base values depending on device type and location\n",
        "    if device_id == 1:  # Living Room\n",
        "        temp_base, humid_base, press_base, light_base = 22.0, 45.0, 1013.0, 60.0\n",
        "    elif device_id == 2:  # Kitchen\n",
        "        temp_base, humid_base, press_base, light_base = 23.5, 50.0, 1013.0, 70.0\n",
        "    elif device_id == 3:  # Outdoor\n",
        "        temp_base, humid_base, press_base, light_base = 18.0, 65.0, 1012.0, 90.0\n",
        "    elif device_id == 4:  # Bedroom\n",
        "        temp_base, humid_base, press_base, light_base = 21.0, 40.0, 1013.0, 30.0\n",
        "    else:\n",
        "        temp_base, humid_base, press_base, light_base = 20.0, 50.0, 1013.0, 50.0\n",
        "\n",
        "    # Add random variations\n",
        "    temperature = temp_base + random.uniform(-2.0, 2.0)\n",
        "    humidity = humid_base + random.uniform(-5.0, 5.0)\n",
        "    pressure = press_base + random.uniform(-1.0, 1.0)\n",
        "    light_level = light_base + random.uniform(-10.0, 10.0)\n",
        "\n",
        "    return (None, device_id, now, temperature, humidity, pressure, light_level)\n",
        "\n",
        "# Simulate data collection over a period\n",
        "print(\"\\nSimulating IoT data collection...\")\n",
        "\n",
        "# Insert some historical data\n",
        "historical_data = []\n",
        "now = datetime.datetime.now()\n",
        "\n",
        "for day in range(7):  # Past week\n",
        "    for hour in range(0, 24, 3):  # Every 3 hours\n",
        "        timestamp = (now - datetime.timedelta(days=day, hours=hour)).strftime('%Y-%m-%d %H:%M:%S')\n",
        "        for device_id in range(1, 5):\n",
        "            reading = generate_sensor_reading(device_id)\n",
        "            # Replace timestamp with historical one\n",
        "            historical_data.append((None, device_id, timestamp) + reading[3:])\n",
        "\n",
        "# Add the data to the database\n",
        "iot_db.executemany('''\n",
        "INSERT INTO sensor_data VALUES (?, ?, ?, ?, ?, ?, ?)\n",
        "''', historical_data)\n",
        "iot_db.commit()\n",
        "\n",
        "# Simulate real-time data collection\n",
        "print(\"Starting real-time sensor data collection...\")\n",
        "for i in range(5):  # Collect 5 readings in real-time\n",
        "    for device_id in range(1, 5):\n",
        "        reading = generate_sensor_reading(device_id)\n",
        "        iot_db.execute('''\n",
        "        INSERT INTO sensor_data VALUES (?, ?, ?, ?, ?, ?, ?)\n",
        "        ''', reading)\n",
        "    iot_db.commit()\n",
        "    print(f\"Collected readings from all sensors (iteration {i+1}/5)\")\n",
        "    time.sleep(1)  # Simulate 1-second delay between readings\n",
        "\n",
        "# Query the data for analysis\n",
        "cursor = iot_db.cursor()\n",
        "\n",
        "# Get the latest reading for each device\n",
        "print(\"\\nLatest sensor readings:\")\n",
        "cursor.execute('''\n",
        "SELECT d.name, s.timestamp, s.temperature, s.humidity, s.pressure, s.light_level\n",
        "FROM sensor_data s\n",
        "JOIN devices d ON s.device_id = d.id\n",
        "WHERE s.timestamp = (\n",
        "    SELECT MAX(timestamp) FROM sensor_data WHERE device_id = s.device_id\n",
        ")\n",
        "''')\n",
        "\n",
        "latest_readings = cursor.fetchall()\n",
        "for reading in latest_readings:\n",
        "    print(f\"{reading[0]} ({reading[1]}): Temp: {reading[2]:.1f}°C, Humidity: {reading[3]:.1f}%, Pressure: {reading[4]:.1f} hPa, Light: {reading[5]:.1f}%\")\n",
        "\n",
        "# Calculate average values by device\n",
        "print(\"\\nAverage values by device:\")\n",
        "cursor.execute('''\n",
        "SELECT d.name,\n",
        "       AVG(s.temperature) as avg_temp,\n",
        "       AVG(s.humidity) as avg_humid,\n",
        "       AVG(s.pressure) as avg_press,\n",
        "       AVG(s.light_level) as avg_light\n",
        "FROM sensor_data s\n",
        "JOIN devices d ON s.device_id = d.id\n",
        "GROUP BY s.device_id\n",
        "''')\n",
        "\n",
        "avg_readings = cursor.fetchall()\n",
        "for reading in avg_readings:\n",
        "    print(f\"{reading[0]}: Avg Temp: {reading[1]:.1f}°C, Avg Humidity: {reading[2]:.1f}%, Avg Pressure: {reading[3]:.1f} hPa, Avg Light: {reading[4]:.1f}%\")\n",
        "\n",
        "# Find temperature anomalies (more than 2 degrees from the average)\n",
        "print(\"\\nTemperature anomalies:\")\n",
        "for device_id in range(1, 5):\n",
        "    cursor.execute('''\n",
        "    SELECT d.name, s.timestamp, s.temperature,\n",
        "           (SELECT AVG(temperature) FROM sensor_data WHERE device_id = ?) as avg_temp\n",
        "    FROM sensor_data s\n",
        "    JOIN devices d ON s.device_id = d.id\n",
        "    WHERE s.device_id = ? AND ABS(s.temperature - (SELECT AVG(temperature) FROM sensor_data WHERE device_id = ?)) > 2\n",
        "    ORDER BY s.timestamp DESC\n",
        "    LIMIT 5\n",
        "    ''', (device_id, device_id, device_id))\n",
        "\n",
        "    anomalies = cursor.fetchall()\n",
        "    if anomalies:\n",
        "        for anomaly in anomalies:\n",
        "            print(f\"{anomaly[0]} at {anomaly[1]}: Temp {anomaly[2]:.1f}°C (Average: {anomaly[3]:.1f}°C)\")\n",
        "\n",
        "# Close the database connection\n",
        "iot_db.close()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub31hQDQ4eHh",
        "outputId": "1f14cdcb-3650-40b0-d656-6afcb2548bfb"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Simulating IoT data collection...\n",
            "Starting real-time sensor data collection...\n",
            "Collected readings from all sensors (iteration 1/5)\n",
            "Collected readings from all sensors (iteration 2/5)\n",
            "Collected readings from all sensors (iteration 3/5)\n",
            "Collected readings from all sensors (iteration 4/5)\n",
            "Collected readings from all sensors (iteration 5/5)\n",
            "\n",
            "Latest sensor readings:\n",
            "Living Room Sensor (2025-03-29 12:35:18): Temp: 22.7°C, Humidity: 41.5%, Pressure: 1013.5 hPa, Light: 64.8%\n",
            "Kitchen Sensor (2025-03-29 12:35:18): Temp: 23.1°C, Humidity: 51.8%, Pressure: 1012.2 hPa, Light: 69.9%\n",
            "Outdoor Sensor (2025-03-29 12:35:18): Temp: 16.1°C, Humidity: 67.9%, Pressure: 1012.0 hPa, Light: 85.1%\n",
            "Bedroom Sensor (2025-03-29 12:35:18): Temp: 20.4°C, Humidity: 38.0%, Pressure: 1012.0 hPa, Light: 35.5%\n",
            "\n",
            "Average values by device:\n",
            "Living Room Sensor: Avg Temp: 21.9°C, Avg Humidity: 44.8%, Avg Pressure: 1013.1 hPa, Avg Light: 59.3%\n",
            "Kitchen Sensor: Avg Temp: 23.4°C, Avg Humidity: 50.1%, Avg Pressure: 1013.0 hPa, Avg Light: 69.1%\n",
            "Outdoor Sensor: Avg Temp: 18.1°C, Avg Humidity: 65.2%, Avg Pressure: 1011.9 hPa, Avg Light: 88.5%\n",
            "Bedroom Sensor: Avg Temp: 21.2°C, Avg Humidity: 39.7%, Avg Pressure: 1013.0 hPa, Avg Light: 31.4%\n",
            "\n",
            "Temperature anomalies:\n",
            "Outdoor Sensor at 2025-03-29 12:35:18: Temp 16.1°C (Average: 18.1°C)\n",
            "Outdoor Sensor at 2025-03-27 21:35:14: Temp 16.0°C (Average: 18.1°C)\n",
            "Outdoor Sensor at 2025-03-26 18:35:14: Temp 16.0°C (Average: 18.1°C)\n",
            "Outdoor Sensor at 2025-03-24 09:35:14: Temp 16.0°C (Average: 18.1°C)\n",
            "Outdoor Sensor at 2025-03-22 21:35:14: Temp 16.0°C (Average: 18.1°C)\n",
            "Bedroom Sensor at 2025-03-29 03:35:14: Temp 19.0°C (Average: 21.2°C)\n",
            "Bedroom Sensor at 2025-03-23 03:35:14: Temp 19.1°C (Average: 21.2°C)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance Optimization\n",
        "Modern SQLite installations are highly optimized, but there are additional steps you can take to improve performance:\n",
        "\n",
        "#### PRAGMA Settings"
      ],
      "metadata": {
        "id": "47N4kluC5Vl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "# Create a new connection\n",
        "conn = sqlite3.connect('optimized.db')\n",
        "\n",
        "# Speed up transactions with WAL mode\n",
        "conn.execute('PRAGMA journal_mode = WAL')\n",
        "\n",
        "# Synchronous setting (0 = OFF, 1 = NORMAL, 2 = FULL, 3 = EXTRA)\n",
        "# Lower values increase speed but with higher risk of corruption in case of system failure\n",
        "conn.execute('PRAGMA synchronous = NORMAL')\n",
        "\n",
        "# Increase cache size (in pages)\n",
        "conn.execute('PRAGMA cache_size = 10000')\n",
        "\n",
        "# Enable memory-mapped I/O (can improve performance for read-heavy applications)\n",
        "conn.execute('PRAGMA mmap_size = 30000000000')\n",
        "\n",
        "# Temporarily disable foreign keys during bulk inserts\n",
        "conn.execute('PRAGMA foreign_keys = OFF')\n",
        "\n",
        "# Batch inserts in a transaction\n",
        "conn.execute('BEGIN TRANSACTION')\n",
        "# ... many insert operations ...\n",
        "conn.execute('COMMIT')\n",
        "\n",
        "# Re-enable foreign keys\n",
        "conn.execute('PRAGMA foreign_keys = ON')\n",
        "\n",
        "# Close the connection\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "8ltHRGYc5Zg2"
      },
      "execution_count": 41,
      "outputs": []
    }
  ]
}